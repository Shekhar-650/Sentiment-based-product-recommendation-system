{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372cda7a",
   "metadata": {
    "id": "372cda7a"
   },
   "source": [
    "# Sentiment-Based Product Recommendation System\n",
    "\n",
    "Starter Jupyter notebook for the Ebuss case study. This notebook walks through:\n",
    "\n",
    "1. Data loading & EDA\n",
    "2. Data cleaning & text preprocessing\n",
    "3. Feature extraction (TF-IDF)\n",
    "4. Training multiple classifiers (Logistic Regression, Random Forest, XGBoost, Naive Bayes)\n",
    "5. Evaluating and selecting best sentiment model\n",
    "6. Building User- and Item-based recommenders\n",
    "7. Re-ranking recommended items using predicted sentiment\n",
    "8. Pickling artifacts and deployment notes\n",
    "\n",
    "Save this notebook and run cells sequentially. Replace file paths as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667919f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "667919f2",
    "outputId": "77e545a9-3735-48db-abe9-a6b1ed125f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shekharanand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## 1) Imports and helper functions\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# XGBoost may not be installed in some environments. If missing, install via pip install xgboost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception as e:\n",
    "    XGBClassifier = None\n",
    "\n",
    "# Recommender utilities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# Text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "print('Imports ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b869b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "e2b869b9",
    "outputId": "181cb747-bafb-4f00-9706-586bb3e48e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2) Load dataset\n",
    "\n",
    "# Update the path to your CSV file if different\n",
    "DATA_PATH = 'sample30.csv'\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}. Upload 'sample30.csv' to /mnt/data or change the path.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109020d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "109020d1",
    "outputId": "4cc93952-0cb2-4a97-8956-1480009ddea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    30000 non-null  object\n",
      " 1   brand                 30000 non-null  object\n",
      " 2   categories            30000 non-null  object\n",
      " 3   manufacturer          29859 non-null  object\n",
      " 4   name                  30000 non-null  object\n",
      " 5   reviews_date          29954 non-null  object\n",
      " 6   reviews_didPurchase   15932 non-null  object\n",
      " 7   reviews_doRecommend   27430 non-null  object\n",
      " 8   reviews_rating        30000 non-null  int64 \n",
      " 9   reviews_text          30000 non-null  object\n",
      " 10  reviews_title         29810 non-null  object\n",
      " 11  reviews_userCity      1929 non-null   object\n",
      " 12  reviews_userProvince  170 non-null    object\n",
      " 13  reviews_username      29937 non-null  object\n",
      " 14  user_sentiment        29999 non-null  object\n",
      "dtypes: int64(1), object(14)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      " id                          0\n",
      "brand                       0\n",
      "categories                  0\n",
      "manufacturer              141\n",
      "name                        0\n",
      "reviews_date               46\n",
      "reviews_didPurchase     14068\n",
      "reviews_doRecommend      2570\n",
      "reviews_rating              0\n",
      "reviews_text                0\n",
      "reviews_title             190\n",
      "reviews_userCity        28071\n",
      "reviews_userProvince    29830\n",
      "reviews_username           63\n",
      "user_sentiment              1\n",
      "dtype: int64\n",
      "Unique users: 24914\n",
      "Unique products: 271\n"
     ]
    }
   ],
   "source": [
    "## 3) Quick EDA\n",
    "\n",
    "# Basic info\n",
    "print(df.info())\n",
    "\n",
    "# Show missing values\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "\n",
    "# Distribution of ratings (if rating column present)\n",
    "if 'overall' in df.columns:\n",
    "    display(df['overall'].value_counts().sort_index())\n",
    "\n",
    "# Number of unique users and products\n",
    "if 'reviews_username' in df.columns:\n",
    "    print('Unique users:', df['reviews_username'].nunique())\n",
    "if 'name' in df.columns:\n",
    "    print('Unique products:', df['name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e619d970",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e619d970",
    "outputId": "4d244dda-5673-4bfd-ccd0-5abfa0937efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n",
      "0    love album good hip hop side current pop sound...\n",
      "1     good flavor review collected part promotion good\n",
      "2                                     good flavor good\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## 4) Text cleaning & preprocessing\n",
    "\n",
    "# We'll create a single text column by combining review title and review text if available\n",
    "text_cols = []\n",
    "if 'reviews_text' in df.columns:\n",
    "    text_cols.append('reviews_text')\n",
    "if 'reviews_title' in df.columns:\n",
    "    text_cols.append('reviews_title')\n",
    "\n",
    "if not text_cols:\n",
    "    # fallback: try common column names\n",
    "    for c in ['reviewText','review_title','text']:\n",
    "        if c in df.columns:\n",
    "            text_cols.append(c)\n",
    "\n",
    "if len(text_cols)==0:\n",
    "    raise ValueError('No text columns found. Update text_cols list to include your review columns.')\n",
    "\n",
    "# create 'text' column\n",
    "df['text'] = df[text_cols].astype(str).apply(lambda x: ' '.join([t for t in x if pd.notnull(t)]), axis=1)\n",
    "\n",
    "# simple cleaning function\n",
    "def clean_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"http\\S+\", \"\", s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    tokens = [w for w in s.split() if w not in STOPWORDS and len(w)>1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# apply cleaning\n",
    "print('Cleaning text...')\n",
    "df['clean_text'] = df['text'].fillna('').apply(clean_text)\n",
    "\n",
    "# sample\n",
    "print(df['clean_text'].iloc[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80331c37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "80331c37",
    "outputId": "0f43959c-7c49-4834-96f1-637e1f213185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 'user_sentiment' column. Counts:\n",
      "sentiment_label\n",
      "positive    26632\n",
      "negative     3367\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joshua</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>love album good hip hop side current pop sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good flavor review collected part promotion good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>good flavor good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rebecca</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>read reviews looking buying one couples lubric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walker557</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>husband bought gel us gel caused irritation fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviews_username                                        name  \\\n",
       "0           joshua   Pink Friday: Roman Reloaded Re-Up (w/dvd)   \n",
       "1        dorothy w  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "2        dorothy w  Lundberg Organic Cinnamon Toast Rice Cakes   \n",
       "3          rebecca            K-Y Love Sensuality Pleasure Gel   \n",
       "4        walker557            K-Y Love Sensuality Pleasure Gel   \n",
       "\n",
       "   reviews_rating sentiment_label  \\\n",
       "0               5        positive   \n",
       "1               5        positive   \n",
       "2               5        positive   \n",
       "3               1        negative   \n",
       "4               1        negative   \n",
       "\n",
       "                                          clean_text  \n",
       "0  love album good hip hop side current pop sound...  \n",
       "1   good flavor review collected part promotion good  \n",
       "2                                   good flavor good  \n",
       "3  read reviews looking buying one couples lubric...  \n",
       "4  husband bought gel us gel caused irritation fe...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Replace your existing \"Create sentiment labels\" cell with this block\n",
    "\n",
    "# Use existing sentiment labels if present, otherwise derive from ratings\n",
    "if 'user_sentiment' in df.columns:\n",
    "    # Normalize values to 'positive'/'negative' strings (in case of different casing)\n",
    "    df['sentiment_label'] = df['user_sentiment'].astype(str).str.strip().str.lower().map(\n",
    "        lambda x: 'positive' if 'pos' in x else ('negative' if 'neg' in x else x)\n",
    "    )\n",
    "    # Keep only rows with positive or negative labels\n",
    "    df_sent = df[df['sentiment_label'].isin(['positive','negative'])].copy()\n",
    "    print(\"Used 'user_sentiment' column. Counts:\")\n",
    "    print(df_sent['sentiment_label'].value_counts())\n",
    "\n",
    "elif 'reviews_rating' in df.columns:\n",
    "    # Map ratings to sentiment (binary). Drop neutral (rating == 3).\n",
    "    df['sentiment_label'] = df['reviews_rating'].apply(\n",
    "        lambda x: 'positive' if float(x) >= 4 else ('negative' if float(x) <= 2 else 'neutral')\n",
    "    )\n",
    "    print(\"Created sentiment_label from 'reviews_rating'. Value counts (including neutral):\")\n",
    "    print(df['sentiment_label'].value_counts())\n",
    "    # Drop neutral reviews for binary classification\n",
    "    df_sent = df[df['sentiment_label'] != 'neutral'].copy()\n",
    "    print('After removing neutral, shape:', df_sent.shape)\n",
    "\n",
    "else:\n",
    "    raise ValueError('No rating or sentiment column found. Provide \"user_sentiment\" or \"reviews_rating\".')\n",
    "\n",
    "# Ensure we have the cleaned text column created earlier. If not, create it from available text columns\n",
    "if 'clean_text' not in df_sent.columns:\n",
    "    text_cols = []\n",
    "    for c in ['reviews_text','reviews_title','reviewText','text']:\n",
    "        if c in df_sent.columns:\n",
    "            text_cols.append(c)\n",
    "    if len(text_cols)==0:\n",
    "        raise ValueError(\"No text column found. Expected one of ['reviews_text','reviews_title','reviewText','text'].\")\n",
    "    df_sent['text'] = df_sent[text_cols].astype(str).apply(lambda x: ' '.join([t for t in x if pd.notnull(t)]), axis=1)\n",
    "    # apply your cleaning function (ensure clean_text function exists in the notebook)\n",
    "    df_sent['clean_text'] = df_sent['text'].fillna('').apply(clean_text)\n",
    "\n",
    "# Final preview\n",
    "df_sent = df_sent.reset_index(drop=True)\n",
    "display(df_sent[['reviews_username','name','reviews_rating','sentiment_label','clean_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14b06b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c14b06b6",
    "outputId": "309d9a9b-b456-40cf-e7dc-696190151127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test sizes: (23999,) (6000,)\n",
      "TF-IDF shapes: (23999, 20000) (6000, 20000)\n",
      "Saved tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "## 6) Train-test split and TF-IDF vectorizer\n",
    "\n",
    "X = df_sent['clean_text'].values\n",
    "y = df_sent['sentiment_label'].map({'negative':0,'positive':1}).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)\n",
    "print('Train/test sizes:', X_train.shape, X_test.shape)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print('TF-IDF shapes:', X_train_tfidf.shape, X_test_tfidf.shape)\n",
    "\n",
    "# Save vectorizer for later\n",
    "pickle.dump(tfidf, open('tfidf_vectorizer.pkl','wb'))\n",
    "print('Saved tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19a55e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b19a55e9",
    "outputId": "0344c05d-12dd-423b-84fa-0a9adb9ad0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: {'accuracy': 0.9051666666666667, 'f1': 0.9491009929331783}\n",
      "RandomForest: {'accuracy': 0.9118333333333334, 'f1': 0.9525092019032229}\n",
      "NaiveBayes: {'accuracy': 0.8916666666666667, 'f1': 0.9422735346358793}\n",
      "XGBoost not available in this environment\n",
      "Best model: RandomForest\n",
      "Saved sentiment_model.pkl\n"
     ]
    }
   ],
   "source": [
    "## 7) Train multiple classifiers and compare\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "yp = lr.predict(X_test_tfidf)\n",
    "results['LogisticRegression'] = {'accuracy': accuracy_score(y_test, yp), 'f1': f1_score(y_test, yp)}\n",
    "print('Logistic:', results['LogisticRegression'])\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "yp = rf.predict(X_test_tfidf)\n",
    "results['RandomForest'] = {'accuracy': accuracy_score(y_test, yp), 'f1': f1_score(y_test, yp)}\n",
    "print('RandomForest:', results['RandomForest'])\n",
    "\n",
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "yp = nb.predict(X_test_tfidf)\n",
    "results['NaiveBayes'] = {'accuracy': accuracy_score(y_test, yp), 'f1': f1_score(y_test, yp)}\n",
    "print('NaiveBayes:', results['NaiveBayes'])\n",
    "\n",
    "# XGBoost (optional)\n",
    "if XGBClassifier is not None:\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb.fit(X_train_tfidf, y_train)\n",
    "    yp = xgb.predict(X_test_tfidf)\n",
    "    results['XGBoost'] = {'accuracy': accuracy_score(y_test, yp), 'f1': f1_score(y_test, yp)}\n",
    "    print('XGBoost:', results['XGBoost'])\n",
    "else:\n",
    "    print('XGBoost not available in this environment')\n",
    "\n",
    "# summary\n",
    "results\n",
    "\n",
    "# Save best model (choose by f1)\n",
    "best_model_name = max(results, key=lambda k: results[k]['f1'])\n",
    "print('Best model:', best_model_name)\n",
    "model_map = {'LogisticRegression': lr, 'RandomForest': rf, 'NaiveBayes': nb}\n",
    "if XGBClassifier is not None:\n",
    "    model_map['XGBoost'] = xgb\n",
    "best_model = model_map[best_model_name]\n",
    "pickle.dump(best_model, open('sentiment_model.pkl','wb'))\n",
    "print('Saved sentiment_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfb6ff1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bfb6ff1",
    "outputId": "c093de5b-6866-4569-e079-45374133557a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings shape: (29937, 3)\n",
      "User-Item matrix shape: (24914, 271)\n",
      "Constructed similarity matrices\n"
     ]
    }
   ],
   "source": [
    "## 8) Build simple User-based and Item-based recommenders (ratings pivot + cosine similarity)\n",
    "\n",
    "# We need a user-item rating matrix. We'll use 'reviews_username', 'name' (product), and 'reviews_rating'.\n",
    "if not all(c in df.columns for c in ['reviews_username','name','reviews_rating']):\n",
    "    raise ValueError('Required columns for recommender not found: reviews_username, name, reviews_rating')\n",
    "\n",
    "ratings = df[['reviews_username','name','reviews_rating']].dropna()\n",
    "ratings = ratings.rename(columns={\n",
    "    'reviews_username':'user',\n",
    "    'name':'item',\n",
    "    'reviews_rating':'rating'\n",
    "})\n",
    "print('Ratings shape:', ratings.shape)\n",
    "\n",
    "# pivot (users Ã— items)\n",
    "user_item = ratings.pivot_table(index='user', columns='item', values='rating')\n",
    "print('User-Item matrix shape:', user_item.shape)\n",
    "\n",
    "# Fill missing with 0 for similarity-based CF (implicit approach)\n",
    "user_item_filled = user_item.fillna(0)\n",
    "\n",
    "# Item-based similarity\n",
    "item_sim = cosine_similarity(user_item_filled.T)\n",
    "item_sim_df = pd.DataFrame(item_sim, index=user_item_filled.columns, columns=user_item_filled.columns)\n",
    "\n",
    "# User-based similarity\n",
    "user_sim = cosine_similarity(user_item_filled)\n",
    "user_sim_df = pd.DataFrame(user_sim, index=user_item_filled.index, columns=user_item_filled.index)\n",
    "\n",
    "print('Constructed similarity matrices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15321fbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15321fbf",
    "outputId": "b8b9f636-38e3-44f6-b84b-dbe9636386f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample user: 00dog3\n",
      "Item-based sample recs: ['Power Crunch Protein Energy Bar Peanut Butter Creme Original', 'Delta Single Handle Shower Faucet', 'Mike Dave Need Wedding Dates (dvd + Digital)', 'Caress Moisturizing Body Bar Natural Silk, 4.75oz', 'Pendaflex174 Divide It Up File Folder, Multi Section, Letter, Assorted, 12/pack']\n",
      "User-based sample recs: []\n"
     ]
    }
   ],
   "source": [
    "## 9) Recommendation functions\n",
    "\n",
    "def recommend_items_item_based(user_id, top_k=20):\n",
    "    # find items the user has rated\n",
    "    if user_id not in user_item.index:\n",
    "        raise ValueError('User not found')\n",
    "    user_ratings = user_item.loc[user_id].dropna()\n",
    "    scores = {}\n",
    "    for item, r in user_ratings.items():\n",
    "        # similar items\n",
    "        sims = item_sim_df[item]\n",
    "        for other_item, sim in sims.items():\n",
    "            if other_item in user_ratings.index:\n",
    "                continue\n",
    "            scores.setdefault(other_item, 0)\n",
    "            scores[other_item] += sim * r\n",
    "    # sort\n",
    "    recs = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return [x[0] for x in recs]\n",
    "\n",
    "\n",
    "def recommend_items_user_based(user_id, top_k=20):\n",
    "    if user_id not in user_item.index:\n",
    "        raise ValueError('User not found')\n",
    "    sims = user_sim_df[user_id]\n",
    "    sim_scores = sims.drop(index=user_id).sort_values(ascending=False)\n",
    "    neighbor_users = sim_scores.head(10).index\n",
    "    # aggregate neighbor ratings\n",
    "    candidates = {}\n",
    "    for nu in neighbor_users:\n",
    "        for item, rating in user_item.loc[nu].dropna().items():\n",
    "            if item in user_item.loc[user_id].dropna().index:\n",
    "                continue\n",
    "            candidates.setdefault(item, []).append(rating)\n",
    "    # average rating\n",
    "    avg_scores = {k: np.mean(v) for k,v in candidates.items()}\n",
    "    recs = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return [x[0] for x in recs]\n",
    "\n",
    "# Example: choose a user from the data\n",
    "sample_user = user_item.index[0]\n",
    "print('Sample user:', sample_user)\n",
    "print('Item-based sample recs:', recommend_items_item_based(sample_user, top_k=5))\n",
    "print('User-based sample recs:', recommend_items_user_based(sample_user, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d59258",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99d59258",
    "outputId": "15ceaa3e-097b-43b4-dbd5-a6ba2a265271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 re-ranked for sample user: [('Pantene Pro-V Expert Collection Age Defy Conditioner', np.float64(0.96375)), ('My Big Fat Greek Wedding 2 (blu-Ray + Dvd + Digital)', np.float64(0.9455096057884231)), ('Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)', np.float64(0.9291848935549724)), ('Delta Single Handle Shower Faucet', np.float64(0.9258333333333333)), ('Clorox Disinfecting Bathroom Cleaner', np.float64(0.9227779140101356))]\n"
     ]
    }
   ],
   "source": [
    "## 10) Rerank top-20 using sentiment model to pick top-5\n",
    "\n",
    "# Load vectorizer and sentiment model\n",
    "vectorizer = pickle.load(open('tfidf_vectorizer.pkl','rb'))\n",
    "model = pickle.load(open('sentiment_model.pkl','rb'))\n",
    "\n",
    "# Function to compute percentage positive reviews for a product\n",
    "def product_positive_pct(product_name):\n",
    "    reviews = df[df['name']==product_name]\n",
    "    if reviews.empty:\n",
    "        return 0.0\n",
    "    texts = reviews['clean_text'].fillna('')\n",
    "    Xv = vectorizer.transform(texts)\n",
    "    # if classifier has predict_proba\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        proba = model.predict_proba(Xv)[:,1]\n",
    "        return proba.mean()\n",
    "    else:\n",
    "        preds = model.predict(Xv)\n",
    "        return np.mean(preds)\n",
    "\n",
    "\n",
    "def recommend_top5_for_user(user_id, base='item', top_k=20):\n",
    "    if base=='item':\n",
    "        candidates = recommend_items_item_based(user_id, top_k=top_k)\n",
    "    else:\n",
    "        candidates = recommend_items_user_based(user_id, top_k=top_k)\n",
    "    scored = [(p, product_positive_pct(p)) for p in candidates]\n",
    "    scored_sorted = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "    return scored_sorted[:5]\n",
    "\n",
    "print('Top-5 re-ranked for sample user:', recommend_top5_for_user(sample_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca55335",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ca55335",
    "outputId": "52102ff4-2711-451b-bd81-7070117fe094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pivot and similarity matrices\n",
      "\n",
      "Deployment files to create:\n",
      "\n",
      "1) model.py  - loads pickled artifacts (tfidf_vectorizer.pkl, sentiment_model.pkl, user_item_pivot.pkl, item_sim.pkl) and exposes functions recommend(username)\n",
      "2) app.py    - Flask app that uses model.py to serve recommendations (POST form with username -> returns top 5 products)\n",
      "3) templates/index.html - simple form to collect username and show results\n",
      "\n",
      "High level app.py example:\n",
      "\n",
      "from flask import Flask, render_template, request\n",
      "import model\n",
      "app = Flask(__name__)\n",
      "\n",
      "@app.route('/', methods=['GET','POST'])\n",
      "def index():\n",
      "    if request.method=='POST':\n",
      "        user = request.form.get('username')\n",
      "        recs = model.recommend_for_user(user)\n",
      "        return render_template('index.html', recommendations=recs)\n",
      "    return render_template('index.html')\n",
      "\n",
      "if __name__=='__main__':\n",
      "    app.run(debug=True)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 11) Save artifacts and deployment notes\n",
    "\n",
    "# Already saved: tfidf_vectorizer.pkl and sentiment_model.pkl\n",
    "# Save user-item pivot and similarity matrices for serving\n",
    "pickle.dump(user_item, open('user_item_pivot.pkl','wb'))\n",
    "pickle.dump(item_sim_df, open('item_sim.pkl','wb'))\n",
    "pickle.dump(user_sim_df, open('user_sim.pkl','wb'))\n",
    "print('Saved pivot and similarity matrices')\n",
    "\n",
    "# Deployment notes (Flask): create three files for deployment\n",
    "notes = '''\n",
    "Deployment files to create:\n",
    "\n",
    "1) model.py  - loads pickled artifacts (tfidf_vectorizer.pkl, sentiment_model.pkl, user_item_pivot.pkl, item_sim.pkl) and exposes functions recommend(username)\n",
    "2) app.py    - Flask app that uses model.py to serve recommendations (POST form with username -> returns top 5 products)\n",
    "3) templates/index.html - simple form to collect username and show results\n",
    "\n",
    "High level app.py example:\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "import model\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "def index():\n",
    "    if request.method=='POST':\n",
    "        user = request.form.get('username')\n",
    "        recs = model.recommend_for_user(user)\n",
    "        return render_template('index.html', recommendations=recs)\n",
    "    return render_template('index.html')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "'''\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "I9efT1x-9DOv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9efT1x-9DOv",
    "outputId": "f45fee0e-87da-41b5-e0fe-55010159d154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NearestNeighbors (this may take time)...\n",
      "saved user_neighbors.pkl\n"
     ]
    }
   ],
   "source": [
    "# generate_user_neighbors.py\n",
    "import pickle, os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# load pivot (users x items) and ensure it's numeric, fillna(0)\n",
    "user_item = pickle.load(open(\"user_item_pivot.pkl\",\"rb\"))\n",
    "X = user_item.fillna(0).astype(np.float32).values  # shape: (n_users, n_items)\n",
    "users = list(user_item.index)\n",
    "\n",
    "n_neighbors = 30  # tune\n",
    "print(\"Fitting NearestNeighbors (this may take time)...\")\n",
    "nbrs = NearestNeighbors(n_neighbors=n_neighbors+1, metric=\"cosine\", algorithm=\"brute\", n_jobs=-1)\n",
    "nbrs.fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "# build top-k dictionary excluding self (index 0)\n",
    "user_neighbors = {}\n",
    "for i, user in enumerate(users):\n",
    "    neigh_idxs = indices[i][1:]   # skip self\n",
    "    neigh_dists = distances[i][1:]\n",
    "    # convert dist -> similarity\n",
    "    neigh_sims = 1.0 - neigh_dists\n",
    "    user_neighbors[user] = [(users[j], float(neigh_sims[k])) for k,j in enumerate(neigh_idxs)]\n",
    "\n",
    "pickle.dump(user_neighbors, open(\"user_neighbors.pkl\",\"wb\"))\n",
    "print(\"saved user_neighbors.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6d0ba",
   "metadata": {
    "id": "ebd6d0ba"
   },
   "source": [
    "## Final notes\n",
    "\n",
    "This notebook is a comprehensive starting point. Next steps\n",
    "\n",
    "- Hyperparameter tuning (GridSearchCV) for each classifier\n",
    "- Handle class imbalance (SMOTE, class weights)\n",
    "- Improve text preprocessing (lemmatization, spelling correction)\n",
    "- Use pretrained sentence embeddings (sentence-transformers) instead of TF-IDF for semantic quality\n",
    "- Use FAISS or Milvus for scalable nearest neighbors on embeddings\n",
    "- Improve recommender by blending collaborative and content-based signals\n",
    "- Build a proper Flask frontend and test locally before deploying to Heroku or similar"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
